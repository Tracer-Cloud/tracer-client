receivers:
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318

  filelog:
    include:
      - "**/*.log"
      - "**/*.nextflow.log"
      - "**/*.command.err"
      - "**/*.command.out"
      - "/var/lib/docker/containers/**/*.log"

    exclude:
      - /proc/*
      - /proc/*/*
      - /proc/*/*/*
      - /sys/*
      - /sys/*/*
      - /sys/*/*/*
      - /dev/*
      - /dev/*/*
      - /dev/*/*/*
      - /snap/*
      - /snap/*/*
      - /snap/*/*/*
      - /System/*
      - /Library/*
      - /Applications/*
      - "**/node_modules/**"
      - "**/.git/**"
      - "**/target/debug/build/**"
      - "**/target/release/build/**"
      - "**/build/**"
      - "**/vendor/**"
      - "**/.cargo/**"
      - "**/.rustup/**"
      - "**/.local/**"
      - "**/.cache/**"
      - "**/tmp/**"
      - "**/var/tmp/**"
      - "**/.terraform/**"
      - "**/.cursor/**"
      - "**/.vscode/**"
      - "**/.android/**"
      - "**/.cocoapods/**"
      - "**/Library/**"

    start_at: beginning
    poll_interval: 5s
    max_log_size: 100MiB
    max_concurrent_files: 4096
    include_file_name: true
    include_file_path: true
    include_file_name_resolved: true
    include_file_path_resolved: true
    fingerprint_size: 2kb
    force_flush_period: 30s

processors:
  batch:
    timeout: 10s
    send_batch_size: 1000
    send_batch_max_size: 2000

  memory_limiter:
    check_interval: 10s
    limit_mib: 512

  resource:
    attributes:
      - key: service.name
        value: "tracer-logger"
        action: insert
      - key: service.version
        value: "1.1.1"
        action: insert
      - key: deployment.environment
        value: "production"
        action: insert
      - key: host.name
        from_attribute: host.name
        action: insert

  transform/logs:
    log_statements:
      - context: log
        statements:
          - set(attributes["file_id"], SHA256(attributes["log.file.path_resolved"])) where attributes["log.file.path_resolved"] != nil
          - set(attributes["file_id"], SHA256(attributes["log.file.path"])) where attributes["file_id"] == nil and attributes["log.file.path"] != nil
          - set(attributes["user_id"], "{{user_id}}")
          - set(attributes["status"], "error") where IsMatch(body, "(?i).*(error|failed|exception|fatal|critical).*")
          - set(attributes["status"], "warning") where IsMatch(body, "(?i).*(warn|warning|caution|deprecated).*")
          - set(attributes["status"], "info") where attributes["status"] == nil
          - set(attributes["log_level"], "INFO")
          - set(attributes["pipeline_name"], "{{pipeline_name}}")
          - set(attributes["run_name"], "{{run_name}}")
          - set(attributes["trace_id"], "{{trace_id}}")
          - set(attributes["span_id"], "{{span_id}}")
          - set(attributes["run_id"], "{{run_id}}")
          - set(attributes["organization_id"], "{{organization_id}}")
          - set(attributes["organization_slug"], "{{organization_slug}}")
          - set(attributes["user_email"], "{{user_email}}")
          - set(attributes["log_file_path"], attributes["log.file.path"]) where attributes["log.file.path"] != nil
          - set(attributes["file_name"], attributes["log.file.name"]) where attributes["log.file.name"] != nil
          - set(attributes["log.file.name_resolved"], attributes["log.file.name_resolved"]) where attributes["log.file.name_resolved"] != nil
          - set(attributes["log.file.path_resolved"], attributes["log.file.path_resolved"]) where attributes["log.file.path_resolved"] != nil
          - set(attributes["log_message"], body)
          - set(attributes["data_stream.dataset"], "default")
          - set(attributes["data_stream.namespace"], "namespace")
          - set(attributes["data_stream.type"], "record")

  transform/metrics:
    metric_statements:
      - context: datapoint # resource (or use this)
        statements:
          - set(attributes["trace_id"], "{{trace_id}}")
          - set(attributes["span_id"], "{{span_id}}")
          - set(attributes["run_id"], "{{run_id}}")
          - set(attributes["organization_id"], "{{organization_id}}")
          - set(attributes["organization_slug"], "{{organization_slug}}")
          - set(attributes["user_id"], "{{user_id}}")
          - set(attributes["user_email"], "{{user_email}}")
          - set(attributes["pipeline_name"], "{{pipeline_name}}")
          - set(attributes["run_name"], "{{run_name}}")

exporters:
  otlphttp/logs:
    endpoint: "{{otel_endpoint}}"
    headers:
      Content-Type: "application/json"
      x-organization-slug: "{{organization_slug}}"
      x-organization-id: "{{organization_id}}"
    timeout: 60s
    retry_on_failure:
      enabled: true
      initial_interval: 10s
      max_interval: 60s
      max_elapsed_time: 600s
    sending_queue:
      enabled: true
      num_consumers: 2
      queue_size: 2000
    tls:
      insecure: false
    encoding: json

  otlphttp/metrics:
    endpoint: "{{otel_endpoint}}"
    headers:
      x-organization-slug: "{{organization_slug}}"
      x-organization-id: "{{organization_id}}"
    timeout: 30s
    retry_on_failure:
      enabled: true
    tls:
      insecure: false
    encoding: json

  debug:
    verbosity: basic
    sampling_initial: 1
    sampling_thereafter: 1000

service:
  pipelines:
    metrics:
      receivers: [otlp]
      processors: [memory_limiter, resource, transform/metrics, batch]
      exporters: [otlphttp/metrics]

    logs:
      receivers: [filelog]
      processors: [resource, transform/logs, batch]
      exporters: [otlphttp/logs, debug]

  extensions: []

  telemetry:
    logs:
      level: info
